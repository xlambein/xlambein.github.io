<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><style>:where(img){height:auto}</style>
  
  <title>PAW: a programmable and visual audio workstation (submission to LIVE
  2023) — Xavier Lambein's website</title>
  <meta name="description" content="My submission to the LIVE 2023 workshop, detailing a project I’ve been working on.">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <link rel="icon" type="image/svg+xml" href="/assets/img/logo.svg">
  <link rel="icon" type="image/png" href="/assets/img/favicon.png">
  <link rel="stylesheet" href="/assets/css/style.css">
  <link rel="stylesheet" href="/assets/css/code.css">
  <link href="/atom.xml" rel="alternate" title="Xavier Lambein’s blog" type="application/atom+xml">
  <link rel="preload" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css" integrity="sha256-XoaMnoYC5TH6/+ihMEnospgm0J1PM/nioxbOUdnM8HY=" crossorigin="anonymous" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css" integrity="sha256-XoaMnoYC5TH6/+ihMEnospgm0J1PM/nioxbOUdnM8HY=" crossorigin="anonymous"></noscript>
  <link rel="me" href="https://sunny.garden/@xavier">
  <meta property="og:image" content="/assets/img/logo.png">
</head>
<body>
  <nav>
    <a href="/" tabindex="-1" aria-hidden="true"><img src="data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' width='200' height='200'%3e%3cpath fill='%23ff8080' stroke='black' stroke-width='5.4' d='m112.728 100 76.367-76.368v25.456L138.184 100l25.456 25.456h-25.456ZM100 112.728l76.368 76.367h-25.456L100 138.184 74.544 163.64v-25.456ZM87.272 100l-76.367 76.368v-25.456L61.816 100 36.36 74.544h25.456ZM100 87.272 23.632 10.905h25.456L100 61.816l25.456-25.456v25.456Z'/%3e%3c/svg%3e" width="61.2" height="61.2" alt="website logo" id="logo" style="float:left" fetchpriority="high"></a>
    <div id="links">
      <a href="/">Home</a> <a href="/about/">About</a> <a href="/music/">Music</a> <a href="/poems/">Poems</a> <a href="/recipes/">Recipes</a>
    </div>
  </nav>
  <article>
    <header>
      <h1>PAW: a programmable and visual audio workstation (submission to LIVE
      2023)</h1>
      <div class="article-info">
        <time class="pubdate">2023-10-23</time>
        <ul class="tags">
          <li>program</li>
          <li>rust</li>
          <li>music</li>
        </ul>
      </div>
    </header>
    <p>This is an essay I wrote as a submission to the <a href="https://liveprog.org/">LIVE 2023 workshop</a>, a workshop on live
    programming. You may also want to <a href="https://www.youtube.com/live/cBYudbaqHAk?si=Y-vjp5sX_7MvSGQI&amp;t=4816">check
    out the talk I gave at LIVE based on this essay</a>.</p>
    <p>I also gave a follow-up presentation at the <a href="https://chci.pages.dev/aist-seminar/en/5">5th AIST Creative HCI
    Seminar</a> hosted by Jun Kato, alongside Tomoya Matsuura and Baku
    Hashimoto. I highly recommend Tomoya and Baku’s presentations.</p>
    <h1 id="introduction">Introduction</h1>
    <p>In this essay I’ll be presenting my ongoing project, whose working title
    is “PAW”, short for “Programmable dAW”. It’s an exploratory prototype of
    making a DAW where the project state is represented by a program, and a GUI
    is generated from code analysis of this program. PAW is based on my
    experience with traditional graphical DAWs, my experience as a programmer,
    and my interest in bidirectional and live programming.</p>
    <p>If you don’t know about DAWs, here’s a primer. “Digital Audio
    Workstations” are an ubiquitous kind of software used by most artists to
    record, mix and produce music. A typical DAW presents the user with a
    skeuomorphic mixing table with “tracks” of audio and MIDI data (e.g., one
    for each instrument). The user can apply effects to these tracks (e.g.,
    distortion, equalizer, delay) and mix them together. DAWs offer powerful
    GUIs to edit these tracks: for example, most of them have a “track editor”,
    where a user can arrange the position of audio and MIDI clips on the
    timeline of each track, to control when each clip is triggered during
    playback.</p>
    <p><img src="ardour.png.jpg" alt="Screenshot from Ardour, a FOSS DAW that I’ve used extensively, and a big source of inspiration." fetchpriority="high" decoding="async" width="960" height="584"></p>
    <p>There’s another angle to making music on the computer, which is highly
    relevant to this project. Quoting <a href="https://en.wikipedia.org/wiki/Live_coding">Wikipedia</a>, “live coding” is
    the practice of “making programming an integral part of the running
    program”. It’s often used in the context of music, where an artist is on a
    stage, writing a program (usually with <a href="https://www.youtube.com/watch?v=YvsoWehBbec">a projector showing their
    code to the audience</a>), while the program is being executed, producing
    music. This is not limited to audio, and you’ll also find visual artists
    doing the same with e.g. shader programs, to generate and animate graphics.
    Live coding lends itself especially well to generative art, where a small
    amount of code can produce intricate patterns, musical or otherwise.</p>
    <p>PAW positions itself in-between these two approaches. Its roots are in
    live coding: the user is presented with a running program generating audio,
    and is invited to edit it live. However, using special syntax, they can
    specify literal values in the source code to be “interactive”, which
    produces a widget on a separate GUI window. Manipulating this GUI results
    in immediate changes to the audio signal, as well as “writeback” of the
    changed values into the source code. Here’s an example of PAW in
    action:</p>
    <p><video src="demo01.webm" controls=""><a href="demo01.webm">A video of
    PAW.</a></video></p>
    <p>Here’s the plan for the rest of this essay. I will start by explaining
    the limitations I’ve encountered with traditional DAWs and live coding, and
    why I hope PAW can address some of them. Then I’ll show in more details how
    PAW currently works. I’ll move on to presenting similar projects in the
    programming and music spaces. Finally, I will conclude by exploring some of
    my ideas for new features and further improvements.</p>
    <h1 id="the-trouble-with-daws">The trouble with DAWs</h1>
    <p>I started working on PAW after getting frustrated with my experience
    using traditional DAWs as a hobbyist. Most of that frustration has to do
    with managing complexity in the interface. DAWs are intricate pieces of UI,
    which take time to master. I must learn the usage model intended by the
    software designer, and then inevitably hit a wall and resort to “hacks”
    when my needs fall outside of this model.</p>
    <p>This problem is the same as with many GUI-based software: graphical
    interfaces don’t compose very well, and so in order to offer the most
    “power” to the user, the software designers must incorporate a dedicated UI
    to account for every possible need. The result is that the number of
    features and the complexity of the interface scale at the same rate. It
    also means that users will still run into limitations imposed by the
    interface, despite its complexity. Finally, complex software is harder to
    get right and build a mental model for, which means both its designers and
    users will make mistakes in how they write and understand it,
    respectively.</p>
    <p>If we look at programming, we see a different trend: the compositional
    nature of programs implies that a great deal of complexity can be expressed
    with a small set of primitives. Code is often not easy to write and
    understand, but it’s both a smaller and more expressive interface than a
    GUI. For example, many GUIs offer some abstraction capabilities: tracks can
    be linked together and share volume, the user-defined settings of an effect
    can be saved and reused, and so on. However, each of these is ad-hoc, has a
    different UI, and is limited to a specific context. Conversely, a program
    abstracts in more powerful ways that are consistent across contexts: any
    two values can be linked by using a variable, any piece of code can be
    re-used by making a function, and so on. This holds whether the code is an
    effect, a track, a whole piece of music, etc.</p>
    <p>Not only are programming languages composable at the semantic level,
    text-based code is also modular in terms of its <em>representation</em>. A
    text file can be opened in the user’s favorite editor, it’s easy to
    version, conflicts are simple (or, at least, possible) to resolve. Because
    of this, source code is also easier to trust than a GUI’s inner state, and
    the user can have greater confidence that their project won’t change in
    surprising ways<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Strictly speaking, some traditional DAWs
    also benefit from this, since they too store their state as text files on
    disk (e.g., Ardour uses XML files). However, because these formats aren’t
    made with the intent of being read and edited by a human, doing so is
    difficult and error-prone.</p>
    <p>Why isn’t live coding for music more widespread then? Well, there’s the
    fact that programming is not a particularly approachable discipline for
    most people. Putting that important problem aside, coding is also not a
    great medium to visualize things and think spatially. As I said before,
    live coding excels in generative music, because this is an area where
    programmability is a core feature, and a graphical interface is hard to
    design. In most musical contexts however, it’s important to be able to move
    bits of audio around, to visually adjust controls and hear immediate
    results, and so on. Even the simple act of changing a number feels clunky
    in a text editor, while it can be very natural when moving a slider with
    the mouse.</p>
    <p>My hope is that, by using programming as its backbone, and filling the
    “visual gaps” of code with GUI, PAW can begin to provide a solution to the
    respective problems with these two approaches.</p>
    <h1 id="presentation-of-paw">Presentation of PAW</h1>
    <p>PAW is implemented as a <a href="https://microsoft.github.io/language-server-protocol/">language server</a>
    for a custom DSL. The user starts by opening PAW, which shows a
    mostly-empty GUI window. With their text editor of choice, they open a
    source file, and the editor connects to PAW via the language server
    protocol. Immediately, the program is compiled and PAW displays interactive
    widgets derived from static code analysis.</p>
    <p><video src="demo02.webm" controls=""><a href="demo02.webm">Video where a
    user opens PAW, then a text editor (helix). PAW compiles the file and
    displays interactive widgets.</a></video></p>
    <p>The user can now edit the program from their text editor. Like with
    other language servers, syntactic and semantic errors are displayed while
    typing. Saving the file recompiles the program and updates the interactive
    widgets.</p>
    <p><video src="demo03.webm" controls=""><a href="demo03.webm">Video where a
    user edits in a new widget.</a></video></p>
    <p>The user can also manipulate these widgets, which too recompiles<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>
    the program, and updates the source file in the text editor.</p>
    <p><video src="demo04.webm" controls=""><a href="demo04.webm">Video where a
    user interacts with a widget, and it updates the code.</a></video></p>
    <p>Atop the window is a play/pause button. When pressed, the program is run
    on an audio thread managed by <a href="https://jackaudio.org/">JACK</a>,
    generating audio. Changes to the interactive widgets are immediately
    reflected in the audio, just like a traditional DAW.</p>
    <p><video src="demo05.webm" controls=""><a href="demo05.webm">Video where a
    user presses play, and music starts playing. They tweak some widgets, which
    changes the music. They edit the source file and save, which changes the
    music as well.</a></video></p>
    <h2 id="the-dsl">The DSL</h2>
    <p>PAW’s DSL is a simple imperative programming language compiled with
    LLVM. Its syntax is close to Lua’s, and its type system is similar to
    Elm’s. It was designed with the goal of being relatively fast and not
    garbage-collected, in order to be usable for sample-level audio
    programming.</p>
    <p>Users can declare values to be interactive by wrapping them inside an
    <code>$interactive(...)</code> expression, as follows:</p>
    <pre><code>let mute = $checkbox(true)</code></pre>
    <p>In the example above, PAW would display a checkbox widget that has been
    checked. Clicking on the widget would uncheck it, and change the source
    code to <code>$checkbox(false)</code>.</p>
    <p>Interactive expressions can be parameterized as follows:</p>
    <pre><code>let volume = $slider(0.5)(0.01, 2.0)</code></pre>
    <p>Which would display a slider with a current value of <code>0.5</code>,
    and a range of <code>0.01</code> to <code>2.0</code>.</p>
    <h2 id="a-track-editor">A track editor.</h2>
    <p>Such widgets can have arbitrary complexity. As mentioned above, a common
    feature of DAWs is the track editor, where horizontal tracks display audio
    and MIDI clips along the time axis. In PAW’s DSL, we represent audio and
    MIDI tracks as follows:</p>
    <pre><code>let guitar = {
  -- Name of the track, used for recording
  name = "Guitar",
  -- Kind of track, currently either `#mono` or `#midi`
  kind = #mono,
  -- Clips in that track
  clips = [
    -- `src` is the audio file
    -- `start` and `end` are a slice of that file, in audio samples
    -- `location` is the offset on the track at which this clip is located
    {src = "Guitar 001.wav", start = 1234, end = 5678, location = 0},
    -- Another clip
    {src = "Guitar 002.wav", start = 5678, end = 91011, location = 6000},
  ],
}</code></pre>
    <p>Such a track can be wrapped inside <code>$track(...)</code> to make it
    appear in PAW. The user can then drag the clips around and resize them, and
    even record new clips.</p>
    <p><video src="demo06.webm" controls=""><a href="demo06.webm">Video of a
    user editing a track.</a></video></p>
    <p>Note that the track editor is quite limited, compared to most modern
    DAWs. As an example, it lacks the ability to import a clip from an existing
    file. However, because a PAW project is just a program’s source code, this
    missing feature is not a dealbreaker: there’s always the escape hatch of
    looking up the file name and manually adding it in the source.</p>
    <p>This is the power of using code as a primary medium. Anything the user
    wants to do, they can accomplish—albeit sometimes with great difficulty.
    Therefore, PAW’s graphical syntax extensions need only to support
    operations where a GUI is critical for useability.</p>
    <h1 id="similar-works-and-inspirations">Similar works and inspirations</h1>
    <p>There’s a long history of augmenting programming with various forms of
    visual and interactive elements. I’ll now look into a few selected projects
    in that space, all of which have influenced my work, and compare them to
    PAW.</p>
    <h2 id="program-synthesis-and-sketch-n-sketch">Program synthesis and
    Sketch-n-Sketch</h2>
    <p><img src="sns.png.webp" alt="Screenshot of Sketch-n-Sketch, showing the source code on the left, and the drawing it produces on the right." loading="lazy" decoding="async" width="816" height="546"></p>
    <p>My initial source of inspiration, <a href="https://ravichugh.github.io/sketch-n-sketch/">Sketch-n-Sketch</a> is a
    direct manipulation programming system for creating HTML and SVG documents.
    In Sketch-n-Sketch, the user writes code in a text area on the
    left-hand-side, and the output of their program, an SVG drawing, is
    displayed on the right-hand-side (see figure above).</p>
    <p>Importantly, this output comes with <em>signifiers</em>, of the kind
    found in traditional SVG drawing applications. These allow the user to
    move, resize, and generally interact with the drawing. Doing so is
    immediately reflected in the source code by computing and applying a
    program transformation.</p>
    <p>Those transformations are often non-trivial: where PAW requires you to
    specify exactly which literals in the program are interactive,
    Sketch-n-Sketch needs no such guidance. For example, when resizing a shape,
    it will go to great lengths to figure out exactly where that size was
    defined, effectively “running the program in reverse”, and apply the change
    there.</p>
    <p>This approach does not translate directly to music, because the output,
    an audio signal, cannot (as far as I can imagine) lend itself to direct
    manipulation. Instead, some GUI acts as a proxy for direct manipulation of
    the output. This idea is explored by Mark Santolucito in <a href="https://2020.splashcon.org/details/live-2020-papers/5/Exploring-Human-in-the-loop-Program-Synthesis-with-Live-Coding">
    “Human-in-the-loop Program Synthesis for Live Coding”</a>, where the user
    can simultaneously interact with a graphical drum sequencer and the
    JavaScript source code it represents.</p>
    <p>Compared to these projects, the logic behind PAW is relatively simple:
    it doesn’t do program synthesis, and interactivity is syntactically
    restricted to specify areas of the code. However, I don’t think this is
    necessarily a bad thing: because of it, PAW’s “mental model” is simpler to
    grasp, and the user has full control over what is interactive, and in which
    ways. Complex Sketch-n-Sketch programs generate equally complex nested
    layers of signifiers, and managing this sprawl is a major concern that PAW
    doesn’t suffer from nearly as much.</p>
    <h2 id="hazels-livelits-and-andersens-visual-syntax">Hazel’s livelits and
    Andersen’s visual syntax</h2>
    <p>Probably the closest project to PAW, and another major source of
    inspiration<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, is Hazel’s <a href="https://hazel.org/papers/livelits-paper.pdf">livelits</a>. These are
    syntactic elements that expand to a literal, and which generate a GUI
    widget inside the Hazel editor for manipulating that literal. Livelits are
    “live”, meaning they generate closures that are re-evaluated as the GUI
    changes, in order to provide direct feedback of these changes. They are
    also composable: livelits can embed text fields which may contain any Hazel
    source code, including other livelits. They can be user-defined and
    partially applied.</p>
    <p>Unlike PAW, livelits are embedded inside the editor, hiding the actual
    literal they represent. At runtime, they are expanded like a macro, whereas
    PAW’s interactive literals are “pass-through” (there’s no expansion), which
    simplifies type checking a little. It also means any existing literal can
    be made interactive, and any interactive literal can be made static again,
    without semantic change to the program. A trade-off is that some literals
    (e.g., the tracks) can end up taking a lot of space in the source code, for
    little value.</p>
    <p>In her paper <a href="https://dl.acm.org/doi/10.1145/3428290">“Adding
    interactive visual syntax to textual code”</a>, Leif Andersen approaches
    this space from a different angle. Her work focuses on creating syntax
    extension (aka, macros) for the Racket language, which expand to visual
    interactive widgets directly in the code editor, DrRacket. Where
    traditional macros are “compile-time”, Andersen’s visual syntax are
    “edit-time”.</p>
    <p>A major difference from livelits is that they lack the “live” element.
    They are implemented as a compiler pass which is executed in the editor,
    and the code they produce is static. In that sense, they are “editor
    extensions”, not directly connected or affecting the execution of a running
    program.</p>
    <p>In its current form, PAW is closer to Andersen’s work than to livelits.
    The semantics of PAW’s interactives is that they modify the source code
    itself, and don’t affect running programs. It just so happens that audio
    processing requires running a signal processing function in a loop, which
    means it’s easy to hot-swap one program for another between two function
    calls, giving the impression of liveness.</p>
    <h2 id="faust">Faust</h2>
    <p>Unlike the previous works I discussed, Faust is not a bidirectional
    programming project. Instead, it’s a programming language and development
    environment for sound synthesis and audio processing.</p>
    <p>Faust has a large library of digital signal processing functions, which
    users can connect together to form audio processing graphs. Being purely
    functional, the language lets users write such programs in a declarative
    way. It’s vastly more rich and usable than PAW’s DSL, and a great source of
    inspiration for further improvements to the language.</p>
    <p>Notable for the context of this essay, Faust includes a GUI library to
    make programs interactive. Here’s an example, which produces three sliders
    for controlling an audio filter:</p>
    <pre class="faust"><code>import("stdfaust.lib");
ctFreq = hslider("cutoffFrequency",500,50,10000,0.01);
q = hslider("q",5,1,30,0.1);
gain = hslider("gain",1,0,1,0.01);
process = no.noise : fi.resonlp(ctFreq,q,gain);</code></pre>
    <p>However, unlike PAW and other similar projects, these widgets are not
    based on code analysis and synthesis: it’s a domain-specific library for
    writing GUIs for audio plugins.</p>
    <h2 id="the-roc-programming-language">The Roc programming language</h2>
    <p>Finally, in terms of both PAW’s structure and its DSL, a major source of
    inspiration has been the novel <a href="https://www.roc-lang.org/">Roc</a>
    programming language, which is an extension of the model of <a href="https://elm-lang.org/">Elm</a> and its <a href="https://guide.elm-lang.org/architecture/">famous architecture</a>. Roc is
    a work-in-progress programming language for writing applications in which
    the domain-specific complexity is abstracted away into a “platform”, which
    is written in some other language (Rust, C, etc.), and users of a platform
    get to write their application in the simpler Roc language.</p>
    <p>PAW’s architecture is similar to Roc’s: the “platform” is a Rust audio
    processing environment, and the “application logic” is a separate program
    in a specific DSL, authored by the user. Interestingly, the Roc team
    <a href="https://github.com/roc-lang/roc/blob/a4500e16bdc7926ce894a0a57ae9c1da664ee26e/design/editor/editor-ideas.md">
    has plans</a> for a language-specific editor which could support
    code-generated interactive UI, meaning one day PAW could be implemented as
    a Roc platform.</p>
    <h1 id="future-plans">Future plans</h1>
    <p>My current short-term goal is to get PAW to a state where I feel
    comfortable using it for (at least some of) my music composition and
    production. To that effect, I’ve been iterating on PAW, its DSL, and its
    audio library. In its current shape, the project is still quite rough on
    the edges, but I’m hoping to finish ironing out the most glaring kinks in
    the coming months.</p>
    <p>Once I feel reasonably comfortable with the stability and usability of
    PAW, I’d like to get other users to try it, receive feedback to improve the
    project, and (in)validate some of my hypotheses. My target audience is
    going to be artists familiar with programming, although I’d love to get to
    a point where it might be approachable to non-coders. I’m not sure whether
    this can be achieved in PAW’s current form.</p>
    <p>In the longer term, I’m also particularly interested in pushing forward
    the expressiveness of this system. To that effect, I have several ideas for
    future improvements, which I’ll detail below.</p>
    <h2 id="language-improvements">Language improvements</h2>
    <p>The PAW DSL currently leaves a lot to be desired. Being very young, the
    language is still a bit broken, hard to debug, and not always pleasant to
    use. It also suffers from complex and sometimes conflicting requirements:
    because I’m aiming to write as much as possible in this one language, the
    DSL needs to be able to handle low-level, performant audio processing code,
    as well as the higher-level structural code connecting parts together.</p>
    <p>So far, this has lead me to making the DSL mostly imperative, but I’m
    hoping to move closer to a functional language in the future. Recent
    developments, such as automatic memory management with <a href="https://www.microsoft.com/en-us/research/uploads/prod/2020/11/perceus-tr-v1.pdf">
    Perceus</a>, might be helpful to achieve high performance while being safer
    and more declarative.</p>
    <h2 id="embedded-text-editor">Embedded text editor</h2>
    <p>The current setup of using an external editor connected to PAW through
    the LSP was mainly chosen so I wouldn’t have to make a whole text editor,
    which would further blow up the scope of this project<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. While it
    does have the advantage of letting users choose their text editor, I don’t
    love this split between the code and the GUI it induces. In the future, it
    might be worth looking into embedding an editor directly into PAW, which
    could display widgets inline like livelits.</p>
    <p>Some text editors, like Vim and Kakoune, can be used in a client/server
    fashion, where a client sends keypresses to a server and receives text to
    display. PAW could embed such a client into a text area, turning it into a
    powerful text editor with very little effort.</p>
    <h2 id="bespoke-widgets-written-in-the-paw-dsl">Bespoke widgets written in
    the PAW DSL</h2>
    <p>Currently, all interactive widgets are hard-coded into the Rust runtime.
    A major long-term goal for PAW is to let users write their own widgets
    directly in the PAW DSL, such that they may be packaged alongside libraries
    to provide domain-specific UI.</p>
    <p>Here’s a tentative example of writing a custom checkbox widget, in an
    immediate GUI style:</p>
    <pre><code>fn checkbox(ctx: GuiContext, checked: Bool) -&gt; Option&lt;Bool&gt;
    let rect = {width = 20.0, height = 20.0, x = 0.0, y = 0.0}

    -- Draw the outer square
    rectangle(ctx, rect, WHITE, BLACK)
    if checked then
        -- Draw an inner square if checked
        let rect = {width = 16.0, height = 16.0, x = 2.0, y = 2.0}
        rectangle(ctx, rect, WHITE, WHITE)
    end

    -- Handle interactions
    if clicked(ctx, rect) then
        -- Value has changed
        #some(!checked)
    else
        -- Nothing to declare
        #none
    end
end</code></pre>
    <p>Note that, unlike a macro, this function does not take an AST as input,
    and instead accepts the actual typed literal value. This is possible
    because PAW’s interactives are “pass-through” and don’t do any syntax
    expansion. Whether doing expansion is desirable in this context is unclear
    to me. Macros can be powerful, but they also obfuscate the actual value in
    the code, and they make type checking trickier.</p>
    <p>Code for these widgets is not relevant to the actual audio runtime of
    PAW, and conversely audio processing code is not needed for the GUI.
    Therefore, the two should ideally be separated in both their scoping and
    their compilation targets. Racket’s <a href="https://docs.racket-lang.org/guide/phases.html">phase system</a> looks to
    be a good solution to this problem—it’s indeed the one used by Andersen in
    her “visual syntax”, mentioned above.</p>
    <h2 id="improve-the-syntax-for-interactive-expressions">Improve the syntax
    for interactive expressions</h2>
    <p>My experience with the current interactive expressions is that they are
    quite heavy in terms of syntax. The user is asked to specify what needs to
    be interactive, the widget to use, and the parameters to apply. To
    illustrate, here’s a simple low-pass filter which is applied to a sample.
    The filter is parameterized by two values, <code>f</code> and
    <code>q</code>, which are interactive:</p>
    <pre><code>let params = {
    f = $slider(0.85)(0.0, 0.99, "log"),
    q = $slider(0.35)(0.0, 0.99),
}
let sample = lp_apply(lp_state, params, sample)</code></pre>
    <p>The filter misbehaves if either of these parameters is outside
    <code>[0.0, 1.0)</code>, so it’s important to set the bounds of the sliders
    properly. Unfortunately, the syntax for this is heavy, not DRY, and
    error-prone.</p>
    <p>An option I’m looking into is to infer as much as possible from the type
    of expressions. Here, <code>f</code> and <code>q</code>’s types are
    inferred from <code>lp_apply</code>’s, which is <code>Fn(&amp;LpState, {f:
    F32, q: F32}, F32) -&gt; F32</code>. We could imagine extending the type
    system with extra information that gets carried by type inference. For
    example, we could change the type of <code>params</code> to be <code>{f:
    F32[min=0.0, max=0.99, scale="log"], q: F32[min=0.0, max=0.99]}</code>. The
    code snippet above becomes:</p>
    <pre><code>let params = {
    f = $slider(0.85),
    q = $slider(0.35),
}
let sample = lp_apply(lp_state, params, sample)</code></pre>
    <p>If a user wants to further restrict the range of allowed values, they
    can do so with a type annotation:</p>
    <pre><code>q = $slider(0.35 : F32[min=0.1, max=0.9])</code></pre>
    <p>Coming back to the issues raised above, the user still has to choose the
    way in which they want a value to be interactive. Here the widget is a
    slider, but it could also make sense to use rotating knobs for space
    efficiency, or even in some cases a bare text input that parses a number.
    Regardless, it’s common to use the same kinds of UI elements for the same
    types of value, because it makes the UI consistent. Therefore, we could
    decide to just say “make this value interactive”, and let the exact widget
    be inferred from the type alone:</p>
    <pre><code>let params = {
    f = $0.85,
    q = $0.35,
}
let sample = lp_apply(lp_state, params, sample)</code></pre>
    <p>The user might want to change the widget used for a given type in a
    specific context. For that, we could have a syntax that acts as a “context
    switch”, signaling that we want to change the default widget within a given
    scope.</p>
    <p>At this point, this is starting to look an awful lot like Haskell’s type
    classes or Rust’s traits—with one quirk: here, we are able to declare
    multiple instances/implementations of a class/trait for the same type, and
    choose the one to use for each scope. There are issues with this, which is
    why Haskell and Rust don’t support it. However, it can be done in a sound
    way, see for example <a href="https://www.researchgate.net/publication/303170128_Controlling_the_scope_of_instances_in_Haskell">
    <em>Controlling the scope of instances in Haskell</em></a> by Gontijo and
    Camarão.</p>
    <p>Building on this idea, let’s envision a trait syntax for PAW’s DSL, and
    write a trait for interactive literals:</p>
    <pre><code>trait Interactive
    fn show_widget(GuiContext, Self) -&gt; Option&lt;Self&gt;
end</code></pre>
    <p>This trait has a single function, whose signature is based on the
    previous section’s widget functions. Again, it would only need to exist
    inside the “editor phase”.</p>
    <p>A benefit of this approach is that it enables straightforward
    composition of interactive literals in a generic way. Continuing on the
    same example, we could establish that records themselves implement the
    <code>Interactive</code> trait whenever all their fields do. The
    implementation of <code>show_widget</code> would then display each field’s
    name as a label, alongside a call to that field’s type’s
    <code>show_widget</code>. We could then rewrite the example as:</p>
    <pre><code>let params = ${
    f = 0.85,
    q = 0.35,
}
let sample = lp_apply(lp_state, params, sample)</code></pre>
    <p>and it would group the low-pass filter’s parameters together, display
    them as sliders (if these are the defaults in scope), and label them with
    “f” and “q”.</p>
    <h2 id="generic-track-editor">Generic track editor</h2>
    <p>I’ll conclude with an application of the concepts introduced in the
    previous sections, in order to make a generic track editor. This, I
    believe, illustrates well how the composability of programs can translate
    to GUIs, increasing their modularity.</p>
    <p>Currently in PAW, the track editor is built around audio clips, which
    are just WAV files. But a “clip” is actually a pretty generic concept: it
    is an interface with a “get data at sample location <code>s</code>”
    operation. More formally, using the previous trait syntax:</p>
    <pre><code>trait Clip&lt;t&gt;
    fn sample_at(Self, Sample) -&gt; Option&lt;t&gt;
end</code></pre>
    <p>where <code>t</code> is a universally-quantified type variable. Given
    this, WAV clips are defined as:</p>
    <pre><code>data WavClip { src: String }

impl Clip&lt;F32&gt; for WavClip
    fn sample_at(self: WavClip, s: Sample) -&gt; Option&lt;F32&gt;
        read_wav_file_at(self.src, s)
    end
end

impl Interactive for WavClip
    fn show_widget(ctx: GuiContext, clip: WavClip) -&gt; Option&lt;WavClip&gt;
        -- Show the waveform
        -- [...]

        -- Not actually interactive: moving and resizing the clip is handled by
        -- the track widget.
        #none
    end
end</code></pre>
    <p>Here’s a different example of clip with the same output type, a “sine
    wave clip” that generates a sine signal with a given frequency:</p>
    <pre><code>const SAMPLING_FREQ: F32 = 48000.0

data SineClip { freq: Float }

impl Clip&lt;F32&gt; for SineClip
    fn sample_at(self: SineClip, s: Sample) -&gt; Option&lt;F32&gt;
        sin(2.0 * PI * to_f32(s) / SAMPLING_FREQ * self.freq)
    end
end

impl Interactive for SineClip
    fn show_widget(ctx: GuiContext, clip: SineClip) -&gt; Option&lt;SineClip&gt;
        -- Show a sine wave
        -- [...]

        -- Show a number input to change the frequency
        -- [...]
    end
end</code></pre>
    <p>Tracks are an array of clips, but they also need to store the position
    of each clip on the timeline, as well as the “slice” of that clip which is
    used in the track. We get the following:</p>
    <pre><code>type alias Track&lt;t&gt; = [TrackClip&lt;t&gt;]

data TrackClip&lt;t&gt; = forall c: Clip&lt;t&gt;. {
    clip: c,
    start: Sample,
    end: Sample,
    location: Sample
}</code></pre>
    <p>Here we’re adding more new syntax. <code>forall c: Clip(t)</code> is
    borrowed from Haskell’s existential types, and works similarly to Rust’s
    trait objects (<code>dyn Trait</code>). It makes <code>TrackClip</code>
    generic only on the output type of <code>sample_at</code>, and not on the
    type of the clip itself. This means a track can contain heterogeneous
    clips, as long as they all produce the same type when sampled.</p>
    <p>Tracks themselves are sampled by reading from each clip in turn, until
    one returns a result for the given sample:</p>
    <pre><code>fn sample_track_at(track: Track&lt;t&gt;, s: Sample) -&gt; Option&lt;t&gt;
    for clip in track do
        if clip.location &lt;= s &amp;&amp; s &lt; clip.location + clip.end - clip.start then
            -- If the sample is in bound, read data from it
            let out = sample_at(clip, s - clip.location + clip.start)
            if is_some(out) then return out end
        end
    end
    #none
end</code></pre>
    <p>A track implements <code>Interactive</code> by iterating over its
    visible clips, restricting the viewport to the clip’s size on the timeline,
    and calling the clip’s <code>show_widget</code> implementation. For this we
    also need to extend the trait bounds on <code>TrackClip</code> to require
    <code>Interactive</code>:</p>
    <pre><code>                                    -- 👇 new stuff
data TrackClip&lt;t&gt; = forall c: Clip&lt;t&gt;, c: Interactive. {
    -- [...]
}

impl Interactive for Track
    fn show_widget(ctx: GuiContext, track: Track) -&gt; Option&lt;Track&gt;
        for clip in track do
            -- The rectangle covered by the clip in the timeline
            let clip_rect = -- [...]

            if rect_is_in_viewport(ctx, clip_rect) then
                -- Handle move and resize events
                -- [...]

                -- Show and interact with the clip's inner widget
                let ctx = restrict_viewport(ctx, clip_rect)
                let clip_result = show_widget(ctx, clip.clip)
                if is_some(clip_result) then
                    -- Clip has changed, pass this up to the calling context
                    -- [...]
                end
            end
        end
    end
end</code></pre>
    <p>Now the track widget will display any <code>Interactive</code> clip,
    allowing the user to move and resize them, and passing other events through
    to the clip’s own widget. Users are free to define new types of clips by
    implementing traits, and these will immediately be supported inside the
    track editor widget.</p>
    <p>It’s interesting to note that, since <code>sample_track_at</code> has
    the same signature as <code>Clip</code>’s <code>sample_at</code>,
    <code>Track</code> itself could be made to implement
    <code>Clip</code><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. This means a track could have
    fully-functioning nested tracks as its clips. Whether this is actually
    useful is left as an exercise to the reader.</p>
    <aside id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
      <hr>
      <ol>
        <li id="fn1">
          <p>To be fair, a properly written GUI application will accurately
          represent its inner state and never surprise the user. However, as
          I’m sure most users of complex GUI programs have experienced, this is
          not always the case. For example, most WYSIWYG word processors I’ve
          used lack transparency in terms of their inner representation of
          formatting and structure. Consequently, it’s common to start typing
          text somewhere, only to find the font’s <span style="font-family:sans-serif">mysteriously changed</span>, or the text is
          now <em>emphasized</em>, because previous formatting was left there
          in an invisible way. Again, this is not impossible to fix, but as
          I’ve argued above, I believe the complex nature of GUIs means they
          require a greater effort on the application authors’ part to ensure
          stability and transparency of the hidden state.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p>
        </li>
        <li id="fn2">
          <p>In practice, recompiling each time a value changes is needlessly
          slow and computationally intensive. Instead, the PAW compiler
          actually produces a shared library with symbols corresponding to each
          interactive value, and manipulating the widgets updates these symbols
          in the shared library.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p>
        </li>
        <li id="fn3">
          <p>Among other things, this is where the <code>$</code>-notation for
          interactive values was stolen.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p>
        </li>
        <li id="fn4">
          <p>In an earlier prototype of PAW, I did have an embedded text area
          which served as an editor. However, the experience of writing code
          with it was so unpleasant that I always ended up opening files in Vim
          for anything non-trivial. For that reason, I eventually got rid of
          it, in favour of using the LSP with an external editor.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p>
        </li>
        <li id="fn5">
          <p>And in fact, we could implement <code>Clip&lt;t&gt;</code> and
          <code>Interactive</code> for <code>Fn(Sample) -&gt; t</code>, making
          any fitting function be a clip.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p>
        </li>
      </ol>
    </aside>
  </article>
  <script type="module" src="/assets/js/mastodon-comments.js"></script>
  <mastodon-comments host="sunny.garden" user="xavier" toot-id="111294532997712793"></mastodon-comments>


</body></html>